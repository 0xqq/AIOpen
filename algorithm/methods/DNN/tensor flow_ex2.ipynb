{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1->0 单层网络\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant(1.0, dtype = tf.float32)\n",
    "y = tf.constant(0.5, dtype = tf.float32)\n",
    "\n",
    "w = tf.Variable(1.0,dtype=tf.float32)\n",
    "b = tf.Variable(0.5,dtype=tf.float32)\n",
    "\n",
    "l_net = w*x + b\n",
    "l_out = tf.sigmoid(l_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ loss = \\frac{1}{2}*(y - l_{out})^2 \\space\\space(MSE) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = .5*tf.square(y - l_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 函数\n",
    "$ w = w - \\eta*\\frac{\\partial E}{\\partial w}, \\space\\space b = b - \\eta*\\frac{\\partial E}{\\partial b}$ \n",
    "\n",
    "$ 其中：\\eta = LearningRate $\n",
    "\n",
    "$ \\eta*\\frac{\\partial E}{\\partial w} 为梯度 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LearningRate = 1\n",
    "optimizer = tf.train.GradientDescentOptimizer(LearningRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ compute_gradients返回值为：(\\eta*\\frac{\\partial E}{\\partial w}, w)(\\eta*\\frac{\\partial E}{\\partial b}, b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算梯度值，返回：w梯度，w，b梯度，b\n",
    "# w梯度 = LearningRate*dE/dw\n",
    "# b梯度 = LearningRate*dE/db\n",
    "grad = optimizer.compute_gradients(loss,[w,b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ w = w - \\eta*\\frac{\\partial E}{\\partial w}, \\space\\space b = b - \\eta*\\frac{\\partial E}{\\partial b}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将 w = w - w梯度， b = b - b梯度 计算出来，并应用到grad中\n",
    "grad_delta = optimizer.apply_gradients(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(1000):\n",
    "    sess.run(grad,feed_dict={x:1,y:0})\n",
    "    sess.run(grad_delta, feed_dict={x:1,y:0})\n",
    "    lost_value = sess.run(loss,feed_dict={x:1,y:0})\n",
    "    print sess.run([w,b,l_out]), lost_value\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
